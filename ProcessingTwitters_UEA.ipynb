{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProcessingTwitters_UEA.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoAguiar/DataScienceProgramming/blob/master/ProcessingTwitters_UEA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WauLBPC8wDZb",
        "outputId": "cf069796-1f5f-461f-c8ab-4c2111785ce8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!wget http://tiagodemelo.info/datasets/dados-curso-completo.csv.tar.gz\n",
        "!tar -xvf dados-curso-completo.csv.tar.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-26 20:21:18--  http://tiagodemelo.info/datasets/dados-curso-completo.csv.tar.gz\n",
            "Resolving tiagodemelo.info (tiagodemelo.info)... 108.167.188.189\n",
            "Connecting to tiagodemelo.info (tiagodemelo.info)|108.167.188.189|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143340808 (137M) [application/x-gzip]\n",
            "Saving to: ‘dados-curso-completo.csv.tar.gz’\n",
            "\n",
            "dados-curso-complet 100%[===================>] 136.70M  15.9MB/s    in 9.9s    \n",
            "\n",
            "2020-09-26 20:21:29 (13.8 MB/s) - ‘dados-curso-completo.csv.tar.gz’ saved [143340808/143340808]\n",
            "\n",
            "dados-curso-completo.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4v2ikToDOON",
        "outputId": "09727be6-8810-46a1-e4a5-dd5bc3dae31d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('dados-curso-completo.csv')\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>usuario</th>\n",
              "      <th>apelido</th>\n",
              "      <th>texto</th>\n",
              "      <th>retweet</th>\n",
              "      <th>seguidores</th>\n",
              "      <th>idioma</th>\n",
              "      <th>lugar</th>\n",
              "      <th>pais</th>\n",
              "      <th>sigla</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-23 18:51:14</td>\n",
              "      <td>Gaboardi</td>\n",
              "      <td>fraslee</td>\n",
              "      <td>@BolsonaroSP Cade o fundão deputado??? Congres...</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>pt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-18 03:18:14</td>\n",
              "      <td>Seu Zé da Farmácia</td>\n",
              "      <td>seuzedafarmacia</td>\n",
              "      <td>Em ação preventiva, o Governo do Estado suspen...</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>pt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-29 12:09:27</td>\n",
              "      <td>Marília Oliveira 🇧🇷</td>\n",
              "      <td>Marioliveira_gb</td>\n",
              "      <td>Incrível como os defensores do fim do distanci...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>pt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-04-01 21:11:07</td>\n",
              "      <td>🚩</td>\n",
              "      <td>santosodeto</td>\n",
              "      <td>Fumaça de cigarro pode propagar coronavírus? h...</td>\n",
              "      <td>0</td>\n",
              "      <td>1885</td>\n",
              "      <td>pt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-03-19 17:49:40</td>\n",
              "      <td>Nova Impressão</td>\n",
              "      <td>novaimpressao_</td>\n",
              "      <td>🚨Todos juntos contra COVID-19💪\\n\\nSolicite seu...</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>pt</td>\n",
              "      <td>Brasília</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>BR</td>\n",
              "      <td>-47.8778</td>\n",
              "      <td>-15.77691</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  data              usuario  ... longitude hashtags\n",
              "0  2020-03-23 18:51:14             Gaboardi  ...       NaN       []\n",
              "1  2020-03-18 03:18:14   Seu Zé da Farmácia  ...       NaN       []\n",
              "2  2020-03-29 12:09:27  Marília Oliveira 🇧🇷  ...       NaN       []\n",
              "3  2020-04-01 21:11:07                    🚩  ...       NaN       []\n",
              "4  2020-03-19 17:49:40       Nova Impressão  ... -15.77691       []\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygTXpIYbFPE1",
        "outputId": "3cb69ccf-0116-47a8-e090-40ef6caffd97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "data.describe"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                         data  ...                  hashtags\n",
              "0        2020-03-23 18:51:14  ...                        []\n",
              "1        2020-03-18 03:18:14  ...                        []\n",
              "2        2020-03-29 12:09:27  ...                        []\n",
              "3        2020-04-01 21:11:07  ...                        []\n",
              "4        2020-03-19 17:49:40  ...                        []\n",
              "...                      ...  ...                       ...\n",
              "1658820  2020-03-13 17:26:18  ...                        []\n",
              "1658821  2020-05-12 13:02:34  ...                        []\n",
              "1658822  2020-03-19 18:16:30  ...           ['CORONAVIRUS']\n",
              "1658823  2020-04-07 18:14:45  ...  ['BolsonaroTemRazaoSim']\n",
              "1658824  2020-06-02 16:04:51  ...                        []\n",
              "\n",
              "[1658825 rows x 13 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCv3tsaLTIsm",
        "outputId": "a3034948-2d7c-4c7b-b1f8-1009fa67acb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(data['texto'].isnull().sum())\n",
        "print(data['lugar'].isnull().sum())\n",
        "print(data['lugar'].isna().sum())\n",
        "print(data['pais'].isnull().sum())\n",
        "print(data['pais'].isna().sum())\n",
        "print(data['latitude'].isnull().sum())\n",
        "print(data['longitude'].isna().sum())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1584220\n",
            "1584220\n",
            "1584225\n",
            "1584225\n",
            "1650105\n",
            "1650105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oc0uhpxfaOJ",
        "outputId": "c460b565-828a-4b9f-8260-9756360abc77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "# instalação da biblioteca de tratamento de texto : spacy\n",
        "!pip install spacy\n",
        "#!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download pt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Collecting pt_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n",
            "\u001b[K     |████████████████████████████████| 21.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.1.0)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186282 sha256=ac11f8ca3f0b0333e7104441684f6a6176c9bc920f16c536936966ce07aa884f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r_r9dbaz/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lny5yTrogFhL",
        "outputId": "069cf8aa-1ef8-47bc-c30d-1cb903c975e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load Portuguese tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = spacy.load(\"pt\")\n",
        "\n",
        "# Process whole documents\n",
        "text = (\"Caro amigo. A Fumaça de cigarro pode propagar coronavírus?\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Analyze syntax\n",
        "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
        "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
        "print(\"Split:\", doc.text.split())\n",
        "print(\"Split mais coerente: \",[token for token in doc])\n",
        "print(\"String ao inves de token\", [token.orth_ for token in doc])\n",
        "print(\"pontuação: \",[token.orth_ for token in doc if token.is_punct])\n",
        "print( \"Classificacao: \", [(token.orth_, token.pos_) for token in doc])\n",
        "sentences = [i for i in nlp(text).sents]\n",
        "print(\"sentences:\", sentences)\n",
        "\n",
        "# Find named entities, phrases and concepts\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noun phrases: []\n",
            "Verbs: ['propagar']\n",
            "Split: ['Caro', 'amigo.', 'A', 'Fumaça', 'de', 'cigarro', 'pode', 'propagar', 'coronavírus?']\n",
            "Split mais coerente:  [Caro, amigo, ., A, Fumaça, de, cigarro, pode, propagar, coronavírus, ?]\n",
            "String ao inves de token ['Caro', 'amigo', '.', 'A', 'Fumaça', 'de', 'cigarro', 'pode', 'propagar', 'coronavírus', '?']\n",
            "pontuação:  ['.', '?']\n",
            "Classificacao:  [('Caro', 'PROPN'), ('amigo', 'NOUN'), ('.', 'PUNCT'), ('A', 'DET'), ('Fumaça', 'PROPN'), ('de', 'ADP'), ('cigarro', 'NOUN'), ('pode', 'AUX'), ('propagar', 'VERB'), ('coronavírus', 'PROPN'), ('?', 'PUNCT')]\n",
            "sentences: [Caro amigo., A Fumaça de cigarro pode propagar coronavírus?]\n",
            "Fumaça de cigarro MISC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iKuijMGVVKS"
      },
      "source": [
        "# Visão geral dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MnQh8zaWAVH"
      },
      "source": [
        "\n",
        "\n",
        "1. Devem apresentar um resumo (sumário) com as estatísticas dos dados originais, ou seja, sem\n",
        "qualquer pré-processamento. A apresentação deste tipo de informação relevante para que outras pessoas possam ter uma visão geral dos dados. As estatísticas podem ser apresentadas\n",
        "através de tabelas e/ou gráficos.\n",
        "\n",
        "\n",
        "\n",
        "2. As mensagens foram pré-processadas para que as perguntas (questões) fossem identificadas.\n",
        "Essa coleção de perguntas corresponde ao dataset “DuvidasDB”. A seguir, a equipe deve\n",
        "apresentar as estatísticas sobre esses dados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohzB_PmSXI6Q"
      },
      "source": [
        "# Temas Discutidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koig2FxKXiXQ"
      },
      "source": [
        "As equipes devem fazer uma análise sobre os temas que são debatidos nas perguntas dos\n",
        "postadas pelos usuários. Faça uma análise se as perguntas são relativas aos seguintes temas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3XONM3vXysA"
      },
      "source": [
        "\n",
        "\n",
        "1.   Doença. Quando a pergunta é relativa à doença. Deve-se observar que a doença é identificada por vários nomes. Exemplo: coronavírus, corona, COVID-19, etc.\n",
        "2.   Medicamento. Quando a pergunta é sobre o uso de determinado medicamento no tratamento\n",
        "da doença.\n",
        "3.   Organizações. Quando a pergunta é relativa a uma determinada entidade ou organização.\n",
        "Emissora de TV, Ministério da Saúde ou empresas, são exemplos de organizações.\n",
        "4.   Pessoas. Quando a pergunta é sobre determinada pessoa. Por exemplo, a pergunta pode\n",
        "ser sobre a atuação que determinado político ou pessoa famosa teve durante esse período de\n",
        "pandemia.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y2xd8fFZTb2"
      },
      "source": [
        "# Visão Temporal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wzYGDzzZaw3"
      },
      "source": [
        "Deve-se fazer uma análise temporal das perguntas que formam o dataset DuvidasDB. Pode-se considerar o intervalo temporal de dias, semanas ou meses. A escolha do intervalo de tempo ficará a cargo das equipes. Exemplos de análise temporal: a) houve um aumento no número de perguntas ao longo do tempo? b) houve uma mudança no perfil das perguntas ao longo do tempo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZyulu0gZwTc"
      },
      "source": [
        "# Visão Geográfica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI87aTDQZ6Gh"
      },
      "source": [
        "Deve-se fazer uma análise geográfica (espacial) das perguntas que formam o dataset DuvidasDB.\n",
        "Existem algumas colunas no dataset que trazem a informação das localizações como, por exemplo,\n",
        "o país, estado e cidade. Em alguns tuítes é possível ainda identificar as coordenadas geográficas de latitude e longitude. Exemplo de análise geográfica: a) os usuários de regiões diferentes fazem perguntas com diferentes focos? Por exemplo, será que os usuários de uma região perguntam mais sobre a doença ou sobre o tratamento? Essa análise ainda pode ser realizada em diversos níveis de\n",
        "área (cidade, estado ou região). Além de apresentar a distribuição das dúvidas dos usuários por região, a equipe deverá fazer uma análise dessa distribuição. Por exemplo, apresentar as razões(ou hipóteses) da ocorrência dessa distribuição."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bpogw7JbZzB"
      },
      "source": [
        ""
      ]
    }
  ]
}