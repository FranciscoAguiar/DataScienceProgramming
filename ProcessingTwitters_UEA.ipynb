{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProcessingTwitters_UEA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoAguiar/DataScienceProgramming/blob/master/ProcessingTwitters_UEA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WauLBPC8wDZb",
        "outputId": "496e19a6-f799-4d8c-d2c8-64d2c046d454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!wget http://tiagodemelo.info/datasets/dados-curso-completo.csv.tar.gz\n",
        "!tar -xvf dados-curso-completo.csv.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-01 01:24:56--  http://tiagodemelo.info/datasets/dados-curso-completo.csv.tar.gz\n",
            "Resolving tiagodemelo.info (tiagodemelo.info)... 108.167.188.189\n",
            "Connecting to tiagodemelo.info (tiagodemelo.info)|108.167.188.189|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143340808 (137M) [application/x-gzip]\n",
            "Saving to: ‚Äòdados-curso-completo.csv.tar.gz‚Äô\n",
            "\n",
            "dados-curso-complet 100%[===================>] 136.70M  64.1MB/s    in 2.1s    \n",
            "\n",
            "2020-10-01 01:24:59 (64.1 MB/s) - ‚Äòdados-curso-completo.csv.tar.gz‚Äô saved [143340808/143340808]\n",
            "\n",
            "dados-curso-completo.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4v2ikToDOON",
        "outputId": "5e84f012-d601-45b6-c703-1e63a9bb9904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('dados-curso-completo.csv')\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>usuario</th>\n",
              "      <th>apelido</th>\n",
              "      <th>texto</th>\n",
              "      <th>retweet</th>\n",
              "      <th>seguidores</th>\n",
              "      <th>idioma</th>\n",
              "      <th>lugar</th>\n",
              "      <th>pais</th>\n",
              "      <th>sigla</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-23 18:51:14</td>\n",
              "      <td>Gaboardi</td>\n",
              "      <td>fraslee</td>\n",
              "      <td>@BolsonaroSP Cade o fund√£o deputado??? Congres...</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>pt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-18 03:18:14</td>\n",
              "      <td>Seu Z√© da Farm√°cia</td>\n",
              "      <td>seuzedafarmacia</td>\n",
              "      <td>Em a√ß√£o preventiva, o Governo do Estado suspen...</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>pt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-29 12:09:27</td>\n",
              "      <td>Mar√≠lia Oliveira üáßüá∑</td>\n",
              "      <td>Marioliveira_gb</td>\n",
              "      <td>Incr√≠vel como os defensores do fim do distanci...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>pt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-04-01 21:11:07</td>\n",
              "      <td>üö©</td>\n",
              "      <td>santosodeto</td>\n",
              "      <td>Fuma√ßa de cigarro pode propagar coronav√≠rus? h...</td>\n",
              "      <td>0</td>\n",
              "      <td>1885</td>\n",
              "      <td>pt</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-03-19 17:49:40</td>\n",
              "      <td>Nova Impress√£o</td>\n",
              "      <td>novaimpressao_</td>\n",
              "      <td>üö®Todos juntos contra COVID-19üí™\\n\\nSolicite seu...</td>\n",
              "      <td>0</td>\n",
              "      <td>124</td>\n",
              "      <td>pt</td>\n",
              "      <td>Bras√≠lia</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>BR</td>\n",
              "      <td>-47.8778</td>\n",
              "      <td>-15.77691</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  data              usuario  ... longitude hashtags\n",
              "0  2020-03-23 18:51:14             Gaboardi  ...       NaN       []\n",
              "1  2020-03-18 03:18:14   Seu Z√© da Farm√°cia  ...       NaN       []\n",
              "2  2020-03-29 12:09:27  Mar√≠lia Oliveira üáßüá∑  ...       NaN       []\n",
              "3  2020-04-01 21:11:07                    üö©  ...       NaN       []\n",
              "4  2020-03-19 17:49:40       Nova Impress√£o  ... -15.77691       []\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygTXpIYbFPE1",
        "outputId": "d9b38520-9564-4716-a75b-820153dc4e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "data.describe"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of                         data  ...                  hashtags\n",
              "0        2020-03-23 18:51:14  ...                        []\n",
              "1        2020-03-18 03:18:14  ...                        []\n",
              "2        2020-03-29 12:09:27  ...                        []\n",
              "3        2020-04-01 21:11:07  ...                        []\n",
              "4        2020-03-19 17:49:40  ...                        []\n",
              "...                      ...  ...                       ...\n",
              "1658820  2020-03-13 17:26:18  ...                        []\n",
              "1658821  2020-05-12 13:02:34  ...                        []\n",
              "1658822  2020-03-19 18:16:30  ...           ['CORONAVIRUS']\n",
              "1658823  2020-04-07 18:14:45  ...  ['BolsonaroTemRazaoSim']\n",
              "1658824  2020-06-02 16:04:51  ...                        []\n",
              "\n",
              "[1658825 rows x 13 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCv3tsaLTIsm",
        "outputId": "87bc09f1-bc6b-437d-c9c3-9431660fb112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "total_records = len(data.index)\n",
        "print('Total records:', total_records)\n",
        "\n",
        "print('Number of records without date:', data['data'].isnull().sum())\n",
        "print('Number of records without text:', data['texto'].isnull().sum())\n",
        "\n",
        "no_city_count = data['lugar'].isnull().sum()\n",
        "print('Number of records without city:', no_city_count)\n",
        "print('Percentage of records without city:', (no_city_count/total_records)*100)\n",
        "\n",
        "print(data['pais'].isnull().sum())\n",
        "print(data['pais'].isna().sum())\n",
        "print('lat', data['latitude'].isna().sum())\n",
        "print('lat', data['latitude'].isnull().sum())\n",
        "print(data['longitude'].isna().sum())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total records: 1658825\n",
            "Number of records without date: 0\n",
            "Number of records without text: 0\n",
            "Number of records without city: 1584220\n",
            "Percentage of records without city: 95.50253944810333\n",
            "1584220\n",
            "1584225\n",
            "1584225\n",
            "lat 1650105\n",
            "lat 1650105\n",
            "1650105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oc0uhpxfaOJ",
        "outputId": "0eacc124-73e4-47a9-f749-be0139dfc27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "# instala√ß√£o da biblioteca de tratamento de texto : spacy\n",
        "!pip install spacy\n",
        "#!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download pt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.2.0)\n",
            "Collecting pt_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz (21.2MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21.2MB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from pt_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.2.5-cp36-none-any.whl size=21186282 sha256=9cf8ff0a79f2fc624a2961782f766a1ebc231f8fa47603289da5839858f2d737\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xww2euhb/wheels/ea/94/74/ec9be8418e9231b471be5dc7e1b45dd670019a376a6b5bc1c0\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m‚úî Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lny5yTrogFhL",
        "outputId": "7ac2b947-4732-4be1-9029-45e3303d1c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load Portuguese tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = spacy.load(\"pt\")\n",
        "\n",
        "# Process whole documents\n",
        "text = (\"Caro amigo, A Fuma√ßa de cigarro pode propagar coronav√≠rus?\")\n",
        "doc = nlp(text)\n",
        "\n",
        "# Analyze syntax\n",
        "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
        "print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
        "print(\"Split:\", doc.text.split())\n",
        "print(\"Split mais coerente: \",[token for token in doc])\n",
        "print(\"String ao inves de token\", [token.orth_ for token in doc])\n",
        "print(\"pontua√ß√£o: \",[token.orth_ for token in doc if token.is_punct])\n",
        "print( \"Classificacao: \", [(token.orth_, token.pos_) for token in doc])\n",
        "sentences = [i for i in nlp(text).sents]\n",
        "print(\"sentences:\", sentences)\n",
        "\n",
        "# Find named entities, phrases and concepts\n",
        "for entity in doc.ents:\n",
        "    print(entity.text, entity.label_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noun phrases: []\n",
            "Verbs: ['propagar']\n",
            "Split: ['Caro', 'amigo,', 'A', 'Fuma√ßa', 'de', 'cigarro', 'pode', 'propagar', 'coronav√≠rus?']\n",
            "Split mais coerente:  [Caro, amigo, ,, A, Fuma√ßa, de, cigarro, pode, propagar, coronav√≠rus, ?]\n",
            "String ao inves de token ['Caro', 'amigo', ',', 'A', 'Fuma√ßa', 'de', 'cigarro', 'pode', 'propagar', 'coronav√≠rus', '?']\n",
            "pontua√ß√£o:  [',', '?']\n",
            "Classificacao:  [('Caro', 'PROPN'), ('amigo', 'PROPN'), (',', 'PUNCT'), ('A', 'DET'), ('Fuma√ßa', 'PROPN'), ('de', 'ADP'), ('cigarro', 'NOUN'), ('pode', 'AUX'), ('propagar', 'VERB'), ('coronav√≠rus', 'PROPN'), ('?', 'PUNCT')]\n",
            "sentences: [Caro amigo, A Fuma√ßa de cigarro pode propagar coronav√≠rus?]\n",
            "A Fuma√ßa de cigarro MISC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ANVZvX5xtsw",
        "outputId": "ca423639-e9f3-4c4c-adab-d062f408824e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "for index, row in data.iterrows():\n",
        "  doc2 = nlp(row['texto'])\n",
        "  sentences = [i for i in doc2.sents]\n",
        "  print(\"punctuation: \",[token.orth_ for token in doc2 if token.is_punct])\n",
        "  for sentence in sentences:\n",
        "    print('sentence:', sentence)\n",
        "\n",
        "  print('\\n')\n",
        "  if (index == 4):\n",
        "    break"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "punctuation:  ['?', '?', '?', '.']\n",
            "sentence: @BolsonaroSP Cade o fund√£o deputado??\n",
            "sentence: ?\n",
            "sentence: Congresso est√° sentado em 3BI olhando a pandemia da janela.\n",
            "\n",
            "\n",
            "punctuation:  [',', '.', '‚Ä¶']\n",
            "sentence: Em a√ß√£o preventiva, o Governo do Estado suspendeu as aulas da rede estadual at√© 31 de mar√ßo.\n",
            "sentence: ‚Å£\n",
            "‚Å£\n",
            "\n",
            "sentence: Esta a√ß√£o est√° ali‚Ä¶ https://t.co/EPFXOMtwSY\n",
            "\n",
            "\n",
            "punctuation:  ['‚Ä¶']\n",
            "sentence: Incr√≠vel como os defensores do fim do distanciamento social fazem parecer que as pessoas com alguma doen√ßa pr√©-exis‚Ä¶ https://t.co/oEyXDF9cDy\n",
            "\n",
            "\n",
            "punctuation:  ['?']\n",
            "sentence: Fuma√ßa de cigarro pode propagar coronav√≠rus?\n",
            "sentence: https://t.co/JT1oMiUCXf\n",
            "\n",
            "\n",
            "punctuation:  ['.', '‚Ä¶']\n",
            "sentence: üö®\n",
            "sentence: Todos juntos contra COVID-19üí™\n",
            "\n",
            "\n",
            "sentence: Solicite seu material por e-mail ou WhatsApp.\n",
            "sentence: Caso venha at√© a empresa traga seu ma‚Ä¶ https://t.co/p6wcoomynZ\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iKuijMGVVKS"
      },
      "source": [
        "# Vis√£o geral dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MnQh8zaWAVH"
      },
      "source": [
        "\n",
        "\n",
        "1. Devem apresentar um resumo (sum√°rio) com as estat√≠sticas dos dados originais, ou seja, sem\n",
        "qualquer pr√©-processamento. A apresenta√ß√£o deste tipo de informa√ß√£o relevante para que outras pessoas possam ter uma vis√£o geral dos dados. As estat√≠sticas podem ser apresentadas\n",
        "atrav√©s de tabelas e/ou gr√°ficos.\n",
        "\n",
        "\n",
        "\n",
        "2. As mensagens foram pr√©-processadas para que as perguntas (quest√µes) fossem identificadas.\n",
        "Essa cole√ß√£o de perguntas corresponde ao dataset ‚ÄúDuvidasDB‚Äù. A seguir, a equipe deve\n",
        "apresentar as estat√≠sticas sobre esses dados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohzB_PmSXI6Q"
      },
      "source": [
        "# Temas Discutidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koig2FxKXiXQ"
      },
      "source": [
        "As equipes devem fazer uma an√°lise sobre os temas que s√£o debatidos nas perguntas dos\n",
        "postadas pelos usu√°rios. Fa√ßa uma an√°lise se as perguntas s√£o relativas aos seguintes temas:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3XONM3vXysA"
      },
      "source": [
        "\n",
        "\n",
        "1.   Doen√ßa. Quando a pergunta √© relativa √† doen√ßa. Deve-se observar que a doen√ßa √© identificada por v√°rios nomes. Exemplo: coronav√≠rus, corona, COVID-19, etc.\n",
        "2.   Medicamento. Quando a pergunta √© sobre o uso de determinado medicamento no tratamento\n",
        "da doen√ßa.\n",
        "3.   Organiza√ß√µes. Quando a pergunta √© relativa a uma determinada entidade ou organiza√ß√£o.\n",
        "Emissora de TV, Minist√©rio da Sa√∫de ou empresas, s√£o exemplos de organiza√ß√µes.\n",
        "4.   Pessoas. Quando a pergunta √© sobre determinada pessoa. Por exemplo, a pergunta pode\n",
        "ser sobre a atua√ß√£o que determinado pol√≠tico ou pessoa famosa teve durante esse per√≠odo de\n",
        "pandemia.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y2xd8fFZTb2"
      },
      "source": [
        "# Vis√£o Temporal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wzYGDzzZaw3"
      },
      "source": [
        "Deve-se fazer uma an√°lise temporal das perguntas que formam o dataset DuvidasDB. Pode-se considerar o intervalo temporal de dias, semanas ou meses. A escolha do intervalo de tempo ficar√° a cargo das equipes. Exemplos de an√°lise temporal: a) houve um aumento no n√∫mero de perguntas ao longo do tempo? b) houve uma mudan√ßa no perfil das perguntas ao longo do tempo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZyulu0gZwTc"
      },
      "source": [
        "# Vis√£o Geogr√°fica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI87aTDQZ6Gh"
      },
      "source": [
        "Deve-se fazer uma an√°lise geogr√°fica (espacial) das perguntas que formam o dataset DuvidasDB.\n",
        "Existem algumas colunas no dataset que trazem a informa√ß√£o das localiza√ß√µes como, por exemplo,\n",
        "o pa√≠s, estado e cidade. Em alguns tu√≠tes √© poss√≠vel ainda identificar as coordenadas geogr√°ficas de latitude e longitude. Exemplo de an√°lise geogr√°fica: a) os usu√°rios de regi√µes diferentes fazem perguntas com diferentes focos? Por exemplo, ser√° que os usu√°rios de uma regi√£o perguntam mais sobre a doen√ßa ou sobre o tratamento? Essa an√°lise ainda pode ser realizada em diversos n√≠veis de\n",
        "√°rea (cidade, estado ou regi√£o). Al√©m de apresentar a distribui√ß√£o das d√∫vidas dos usu√°rios por regi√£o, a equipe dever√° fazer uma an√°lise dessa distribui√ß√£o. Por exemplo, apresentar as raz√µes(ou hip√≥teses) da ocorr√™ncia dessa distribui√ß√£o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bpogw7JbZzB"
      },
      "source": [
        ""
      ]
    }
  ]
}