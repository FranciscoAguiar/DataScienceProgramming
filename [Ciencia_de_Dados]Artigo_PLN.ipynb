{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Ciencia de Dados]Artigo_PLN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMndiBUp6xjYnD7eGO0oYE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FranciscoAguiar/DataScienceProgramming/blob/master/%5BCiencia_de_Dados%5DArtigo_PLN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqA1fnhG1XYQ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        "import json\n",
        "import csv\n",
        "import nltk\n",
        "sns.set_style('whitegrid')\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pip"
      ],
      "metadata": {
        "id": "INpMd9yc7B3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U setuptools wheel"
      ],
      "metadata": {
        "id": "lSFk7Dwi72OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"mxnet<2.0.0\""
      ],
      "metadata": {
        "id": "TnEGijCb7_Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon"
      ],
      "metadata": {
        "id": "fQURd6FW8GC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.core.utils.loaders import load_pd"
      ],
      "metadata": {
        "id": "J6hJA4ZVKvGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet')\n",
        "test_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet')\n",
        "subsample_size = 1000  # subsample data for faster demo, try setting this to larger values\n",
        "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
        "train_data.head(10)"
      ],
      "metadata": {
        "id": "AaMNoQbk6khb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['AUTOGLUON_TEXT_TRAIN_WITHOUT_GPU']='1'"
      ],
      "metadata": {
        "id": "1MudvsWABXrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.text import TextPredictor\n",
        "\n",
        "predictor = TextPredictor(label='label', eval_metric='acc', path='./ag_sst')\n",
        "predictor.fit(train_data, time_limit=None)"
      ],
      "metadata": {
        "id": "dBJGRgVu7km0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = predictor.evaluate(test_data)\n"
      ],
      "metadata": {
        "id": "20XOunD_CkBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = predictor.evaluate(test_data, metrics=['acc', 'f1'])\n",
        "print(test_score)"
      ],
      "metadata": {
        "id": "dRyX8hKuDND4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = \"it's a charming and often affecting journey.\"\n",
        "sentence2 = \"It's slow, very, very, very slow.\"\n",
        "predictions = predictor.predict({'sentence': [sentence1, sentence2]})\n",
        "print('\"Sentence\":', sentence1, '\"Predicted Sentiment\":', predictions[0])\n",
        "print('\"Sentence\":', sentence2, '\"Predicted Sentiment\":', predictions[1])"
      ],
      "metadata": {
        "id": "YNIrG_JCDTdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_brasilia = pd.read_csv('brasilia-guru.csv', sep=',')\n",
        "dataset_fortaleza = pd.read_csv('fortaleza-guru.csv', sep=',')\n",
        "dataset_manaus = pd.read_csv('manaus-guru.csv', sep=',')\n",
        "dataset_poa = pd.read_csv('poa-guru.csv', sep=',')\n",
        "dataset_sampa = pd.read_csv('sampa-guru.csv', sep=',')"
      ],
      "metadata": {
        "id": "S253NgenY36w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['name'].unique())"
      ],
      "metadata": {
        "id": "JOkU92s4jpQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(5)"
      ],
      "metadata": {
        "id": "RGUgmLaPjrGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "0kMCVgLBj1s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.drop(columns=['classe'],inplace=True)"
      ],
      "metadata": {
        "id": "-CfkM6fAzX1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"classe\"] = -1"
      ],
      "metadata": {
        "id": "a_4jEJrbviHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head(3)"
      ],
      "metadata": {
        "id": "QMCO1941vnhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_df = dataset.sort_values(by=['addressLocality'], ascending=True)"
      ],
      "metadata": {
        "id": "gy2uX6MLhjnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted_df['addressLocality'].unique())"
      ],
      "metadata": {
        "id": "0jSYl-kyhqhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "iZcHupjqj50W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download()"
      ],
      "metadata": {
        "id": "XIlfIckGlJG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "metadata": {
        "id": "bADSqkp7R3W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handleText(title):\n",
        "  text = title\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  new_lista = []\n",
        "  stop_words = nltk.corpus.stopwords.words(\"portuguese\")\n",
        "  new_lista = [token.lower() for token in tokens if token.lower() not in stop_words]\n",
        "  #print(new_lista)\n",
        "  freq = nltk.FreqDist(new_lista)\n",
        "  #freq.most_common()\n",
        "  return new_lista"
      ],
      "metadata": {
        "id": "hM9RTsU5lEVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food = [\"refeição\",\"almoço\", \"jantar\", \"lanche\", \"culinária\",\"cozinha\", \"gastronomia\", \"ingredientes\", \"cardápio\", \"buffet\", \"prato\",\"degustação\", \"guarnições\", \"acompanhamentos\", \"entradas\", \"sobremessa\", \"petiscos\", \"alimentação\",\"comida\"]"
      ],
      "metadata": {
        "id": "dQcfeL_0lS24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drink = [\"água\", \"vinho\", \"whisky\", \"cachaça\",\"refrigerante\", \"drinque\", \"licor\", \"cerveja\", \"choop\", \"coquetel\", \"suco\", \"caipirinha\", \"café\" , \"capuccino\", \"Chá\", \"Guaraná\"]"
      ],
      "metadata": {
        "id": "iMDfi4LOmwNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service = [\"Atendimento\",\"garçom\",\"Pedido\",\"Vale-refeição\" ,\"Vale-alimentação\",\"delivery\",\"online\",\"aplicativo\",\"evento\",\"Vale refeição\" ,\"Vale alimentação\"]"
      ],
      "metadata": {
        "id": "6sm90FOanWJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price = [\"valor\", \"pagamento\",  \"custo\" , \"gorjeta\", \"conta\", \"preço\", \"despesa\", \"nota fiscal\"]"
      ],
      "metadata": {
        "id": "lhu9dSpVoBSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enviroment = [\"Talheres\",\"Copos\", \"Taças\", \"Guardanapos\", \"Toalha\", \"Decoração\", \"ar condicionado\", \"cozinha\",\"balcão\", \"limpeza\", \"organização\", \"fila\", \"estacionamento\", \"música\", \"Som\",\"espaço\", \"área\", \"estabelecimento\", \"lounge\", \"unidade\", \"pessoas\", \"conforto\", \"segurança\", \"funcionamento\", \"horário\", \"briquedoteca\", \"dj\"]"
      ],
      "metadata": {
        "id": "rWlRx-DDpeDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location = [\"local\", \"lugar\", \"shopping\", \"praia\", \"avenida\", \"rua\", \"prédio\", \"beira mar\", \"região\", \"bairro\"]"
      ],
      "metadata": {
        "id": "rXbKJivpqBdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkString(title,list):\n",
        "  title = title.lower()\n",
        "  words = handleText(title)\n",
        "  result = False\n",
        "  for j in list:\n",
        "    value = j.lower()\n",
        "    if value in words:\n",
        "      result = True\n",
        "      return result\n",
        "  return result   \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U7x_wDHYsIKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addCategory(element, value):\n",
        "  \n",
        "  if (not dataset[\"classe\"][element]):\n",
        "    dataset[\"classe\"][element] = value\n",
        "    return dataset.loc[element], False\n",
        "  else :\n",
        "    register = dataset.loc[element]\n",
        "    #print(register)\n",
        "    register[\"classe\"] = value\n",
        "    return register, True\n",
        "\n"
      ],
      "metadata": {
        "id": "rO1s_QVNUOg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newRegister = []\n",
        "for i in dataset.index:\n",
        "  reviewBody = (dataset[\"reviewBody\"][i])\n",
        "  isPresent = checkString(reviewBody,food)\n",
        "  if isPresent:\n",
        "    category = dataset[\"classe\"][i]\n",
        "    row, newElement = addCategory(i, 0)\n",
        "    if (newElement):\n",
        "      # simply concatenate both dataframes\n",
        "        newRegister.append(row)\n",
        "\n",
        "\n",
        "\n",
        "  isPresent = checkString(reviewBody,drink)\n",
        "\n",
        "  if isPresent:\n",
        "    category = dataset[\"classe\"][i]\n",
        "    row, newElement = addCategory(i, 1)\n",
        "    if (newElement):\n",
        "      # simply concatenate both dataframes\n",
        "        newRegister.append(row)\n",
        "\n",
        "  \n",
        "  isPresent = checkString(reviewBody,service)\n",
        "  \n",
        "  if isPresent:\n",
        "    category = dataset[\"classe\"][i]\n",
        "    row, newElement = addCategory(i, 2)\n",
        "    if (newElement):\n",
        "      # simply concatenate both dataframes\n",
        "        newRegister.append(row)\n",
        "\n",
        "\n",
        "  isPresent = checkString(reviewBody,price)\n",
        "  \n",
        "  if isPresent:\n",
        "    category = dataset[\"classe\"][i]\n",
        "    row, newElement = addCategory(i, 3)\n",
        "    if (newElement):\n",
        "      # simply concatenate both dataframes\n",
        "        newRegister.append(row)\n",
        "\n",
        "\n",
        "  isPresent = checkString(reviewBody,enviroment)\n",
        "  \n",
        "  if isPresent:\n",
        "    category = dataset[\"classe\"][i]\n",
        "    row, newElement = addCategory(i, 4)\n",
        "    if (newElement):\n",
        "      # simply concatenate both dataframes\n",
        "         newRegister.append(row)\n",
        "\n",
        "  \n",
        "  isPresent = checkString(reviewBody,location)\n",
        "  \n",
        "  if isPresent:\n",
        "    category = dataset[\"classe\"][i]\n",
        "    row, newElement = addCategory(i, 5)\n",
        "    if (newElement):\n",
        "      # simply concatenate both dataframes\n",
        "       newRegister.append(row)\n",
        "    \n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "tS9hixy7qWlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtro = dataset.query('reviewId == 607488709')\n"
      ],
      "metadata": {
        "id": "DDnSVcW2wXTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "8aQIYBUmxk-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newRegister"
      ],
      "metadata": {
        "id": "iGc-XHBuxttM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtro"
      ],
      "metadata": {
        "id": "ODIBFV6OTTLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtro[\"reviewBody\"])"
      ],
      "metadata": {
        "id": "HQfW9MeuzRfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.append(newRegister, ignore_index=True)"
      ],
      "metadata": {
        "id": "aDT80HvByOdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.text import TextPredictor"
      ],
      "metadata": {
        "id": "CJuDUR4w1OSq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}